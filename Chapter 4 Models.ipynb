{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/joshuapark/Desktop/Python/DeepLearningFromScratch'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('DeepLearningFromScratch')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.utils import *\n",
    "from Models.base import *\n",
    "from Models.activations import *\n",
    "from Models.layers import *\n",
    "from Models.losses import *\n",
    "from Models.network import *\n",
    "from Models.optimizer import *\n",
    "from Models.parameters import *\n",
    "from Models.trainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load():\n",
    "    os.chdir('Mnist_Data')\n",
    "    with open(\"mnist.pkl\",'rb') as f:\n",
    "        mnist = pickle.load(f)\n",
    "    os.chdir('../')\n",
    "    return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, test_labels = one_hot_encoding(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train - np.mean(x_train)) / np.std(x_train)\n",
    "x_test = (x_test - np.mean(x_test)) / np.std(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------TESTING-------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error Loss with Tanh activation\n",
      "\n",
      "Validation loss at epoch 10 is 0.6110263664268817\n",
      "Validation loss at epoch 20 is 0.4277180845824946\n",
      "Validation loss at epoch 30 is 0.3887247264261846\n",
      "Validation loss at epoch 40 is 0.37431587897259877\n",
      "Validation loss at epoch 50 is 0.3665295656253431\n",
      "\n",
      "Accuracy of model is 72.61%\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error Loss with Tanh activation\\n\")\n",
    "MSE_model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89,\n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10,\n",
    "                  activation=Sigmoid())],\n",
    "    loss=MeanSquaredError(),\n",
    "    seed=20190119)\n",
    "\n",
    "MSE_trainer = Trainer(MSE_model, SGD(.1))\n",
    "MSE_trainer.fit(x_train, train_labels, x_test, test_labels,\n",
    "                epochs=50,\n",
    "                eval_every=10,\n",
    "                batch_size=60,\n",
    "                seed=20190119)\n",
    "print()\n",
    "eval_model_accuracy(MSE_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error Loss with Sigmoid Activation\n",
      "\n",
      "Validation loss at epoch 10 is 0.4327557684139889\n",
      "Validation loss at epoch 20 is 0.3257007540598672\n",
      "Validation loss at epoch 30 is 0.26035902633132046\n",
      "Validation loss at epoch 40 is 0.1997683667828922\n",
      "Validation loss at epoch 50 is 0.17966933281119893\n",
      "\n",
      "Accuracy of model is 89.98%\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Squared Error Loss with Sigmoid Activation\\n\")\n",
    "\n",
    "MSE_model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89,\n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=10,\n",
    "                  activation=Sigmoid())],\n",
    "    loss=MeanSquaredError(),\n",
    "    seed=20190119)\n",
    "\n",
    "MSE_trainer = Trainer(MSE_model, SGD(.1))\n",
    "MSE_trainer.fit(x_train, train_labels, x_test, test_labels,\n",
    "                epochs=50,\n",
    "                eval_every=10,\n",
    "                batch_size=60,\n",
    "                seed=20190119)\n",
    "print()\n",
    "eval_model_accuracy(MSE_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftmaxCrossEntrophy Loss with Tanh Activation\n",
      "\n",
      "Validation loss at epoch 10 is 0.6302739903203189\n",
      "Validation loss at epoch 20 is 0.574231043410204\n",
      "Validation loss at epoch 30 is 0.5488206069695402\n",
      "Validation loss at epoch 40 is 0.5468754432505499\n",
      "Validation loss  increased after epoch 50, previous loss was 0.547; using model from epoch 40\n",
      "\n",
      "Accuracy of model is 91.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"SoftmaxCrossEntrophy Loss with Tanh Activation\\n\")\n",
    "SMCE_model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89,\n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10,\n",
    "                  activation=Linear())],\n",
    "    loss=SoftMaxCrossEntrophy(),\n",
    "    seed=20190119)\n",
    "\n",
    "SMCE_trainer = Trainer(SMCE_model, SGD(.1))\n",
    "SMCE_trainer.fit(x_train, train_labels, x_test, test_labels,\n",
    "                 epochs=50,\n",
    "                 eval_every=10,\n",
    "                 batch_size=60,\n",
    "                 seed=20190119)\n",
    "print()\n",
    "eval_model_accuracy(SMCE_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftmaxCrossEntrophy Loss with Sigmoid Activation\n",
      "\n",
      "Validation loss at epoch 10 is 0.5986143763749157\n",
      "Validation loss at epoch 20 is 0.522880868937497\n",
      "Validation loss at epoch 30 is 0.4861981332330422\n",
      "Validation loss at epoch 40 is 0.47116605111804266\n",
      "Validation loss at epoch 50 is 0.45435970290867755\n",
      "\n",
      "Accuracy of model is 92.11%\n"
     ]
    }
   ],
   "source": [
    "print(\"SoftmaxCrossEntrophy Loss with Sigmoid Activation\\n\")\n",
    "SMCE_model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89,\n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=10,\n",
    "                  activation=Linear())],\n",
    "    loss=SoftMaxCrossEntrophy(),\n",
    "    seed=20190119)\n",
    "\n",
    "SMCE_trainer = Trainer(SMCE_model, SGD(.1))\n",
    "SMCE_trainer.fit(x_train, train_labels, x_test, test_labels,\n",
    "                 epochs=50,\n",
    "                 eval_every=10,\n",
    "                 batch_size=60,\n",
    "                 seed=20190119)\n",
    "print()\n",
    "eval_model_accuracy(SMCE_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftmaxCrossEntrophy Loss with Tanh Activation and Momentum Optimizer\n",
      "\n",
      "Validation loss at epoch 10 is 0.4422109212024509\n",
      "Validation loss at epoch 20 is 0.350612701504347\n",
      "Validation loss at epoch 30 is 0.3437877324460849\n",
      "Validation loss at epoch 40 is 0.3381969638197681\n",
      "Validation loss  increased after epoch 50, previous loss was 0.338; using model from epoch 40\n",
      "\n",
      "Accuracy of model is 95.53%\n"
     ]
    }
   ],
   "source": [
    "print(\"SoftmaxCrossEntrophy Loss with Tanh Activation and Momentum Optimizer\\n\")\n",
    "SMCE_model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89,\n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10,\n",
    "                  activation=Linear())],\n",
    "    loss=SoftMaxCrossEntrophy(),\n",
    "    seed=20190119)\n",
    "\n",
    "SMCE_trainer = Trainer(SMCE_model, SGDMomentum(lr=.1, momentum=.9))\n",
    "SMCE_trainer.fit(x_train, train_labels, x_test, test_labels,\n",
    "                 epochs=50,\n",
    "                 eval_every=10,\n",
    "                 batch_size=60,\n",
    "                 seed=20190119)\n",
    "print()\n",
    "eval_model_accuracy(SMCE_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftmaxCrossEntrophy Loss with Sigmoid Activation and Momentum Optimizer\n",
      "\n",
      "Validation loss at epoch 10 is 0.3707137230974116\n",
      "Validation loss  increased after epoch 20, previous loss was 0.371; using model from epoch 10\n",
      "Validation loss  increased after epoch 30, previous loss was 0.371; using model from epoch 20\n",
      "Validation loss  increased after epoch 40, previous loss was 0.371; using model from epoch 30\n",
      "Validation loss  increased after epoch 50, previous loss was 0.371; using model from epoch 40\n",
      "\n",
      "Accuracy of model is 94.38%\n"
     ]
    }
   ],
   "source": [
    "print(\"SoftmaxCrossEntrophy Loss with Sigmoid Activation and Momentum Optimizer\\n\")\n",
    "SMCE_model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89,\n",
    "                  activation=Sigmoid()),\n",
    "            Dense(neurons=10,\n",
    "                  activation=Linear())],\n",
    "    loss=SoftMaxCrossEntrophy(),\n",
    "    seed=20190119)\n",
    "\n",
    "SMCE_trainer = Trainer(SMCE_model, SGDMomentum(lr=.1, momentum=.9))\n",
    "SMCE_trainer.fit(x_train, train_labels, x_test, test_labels,\n",
    "                 epochs=50,\n",
    "                 eval_every=10,\n",
    "                 batch_size=60,\n",
    "                 seed=20190119)\n",
    "print()\n",
    "eval_model_accuracy(SMCE_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftmaxCrossEntrophy Loss with Tanh Activation and Momentum Optimizer with Linear Decayed Learning\n",
      "\n",
      "Validation loss at epoch 10 is 0.40237630027335136\n",
      "Validation loss at epoch 20 is 0.3428689728032435\n",
      "Validation loss at epoch 30 is 0.28192035939098975\n",
      "Validation loss  increased after epoch 40, previous loss was 0.282; using model from epoch 30\n",
      "Validation loss  increased after epoch 50, previous loss was 0.282; using model from epoch 40\n",
      "\n",
      "Accuracy of model is 95.90%\n"
     ]
    }
   ],
   "source": [
    "print(\"SoftmaxCrossEntrophy Loss with Tanh Activation and Momentum Optimizer with Linear Decayed Learning\\n\")\n",
    "SMCE_model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89,\n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10,\n",
    "                  activation=Linear())],\n",
    "    loss=SoftMaxCrossEntrophy(),\n",
    "    seed=20190119)\n",
    "\n",
    "SMCE_trainer = Trainer(SMCE_model, SGDMomentum(lr=.15, momentum=.9, final_lr=.05, decay_type='linear'))\n",
    "SMCE_trainer.fit(x_train, train_labels, x_test, test_labels,\n",
    "                 epochs=50,\n",
    "                 eval_every=10,\n",
    "                 batch_size=60,\n",
    "                 seed=20190119)\n",
    "print()\n",
    "eval_model_accuracy(SMCE_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftmaxCrossEntrophy Loss with Tanh Activation and Momentum Optimizer with Exponential Decayed Learning\n",
      "\n",
      "Validation loss at epoch 10 is 0.46302786259081696\n",
      "Validation loss at epoch 20 is 0.32337032970530294\n",
      "Validation loss at epoch 30 is 0.28431174906298845\n",
      "Validation loss  increased after epoch 40, previous loss was 0.284; using model from epoch 30\n",
      "Validation loss  increased after epoch 50, previous loss was 0.284; using model from epoch 40\n",
      "\n",
      "Accuracy of model is 96.11%\n"
     ]
    }
   ],
   "source": [
    "print(\"SoftmaxCrossEntrophy Loss with Tanh Activation and Momentum Optimizer with Exponential Decayed Learning\\n\")\n",
    "SMCE_model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89,\n",
    "                  activation=Tanh()),\n",
    "            Dense(neurons=10,\n",
    "                  activation=Linear())],\n",
    "    loss=SoftMaxCrossEntrophy(),\n",
    "    seed=20190119)\n",
    "\n",
    "SMCE_trainer = Trainer(SMCE_model, SGDMomentum(lr=.2, momentum=.9, final_lr=.05, decay_type='exponential'))\n",
    "SMCE_trainer.fit(x_train, train_labels, x_test, test_labels,\n",
    "                 epochs=50,\n",
    "                 eval_every=10,\n",
    "                 batch_size=60,\n",
    "                 seed=20190119)\n",
    "print()\n",
    "eval_model_accuracy(SMCE_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftmaxCrossEntrophy Loss with Tanh Activation and Momentum Optimizer with Exponential Decayed Learning and Glorot\n",
      "Weight Initialization\n",
      "\n",
      "Validation loss at epoch 10 is 0.351782678133956\n",
      "Validation loss at epoch 20 is 0.2799564118646935\n",
      "Validation loss at epoch 30 is 0.2427882451390557\n",
      "Validation loss  increased after epoch 40, previous loss was 0.243; using model from epoch 30\n",
      "Validation loss  increased after epoch 50, previous loss was 0.243; using model from epoch 40\n",
      "\n",
      "Accuracy of model is 96.75%\n"
     ]
    }
   ],
   "source": [
    "print('''SoftmaxCrossEntrophy Loss with Tanh Activation and Momentum Optimizer with Exponential Decayed Learning and Glorot\n",
    "Weight Initialization\\n''')\n",
    "SMCE_model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89,\n",
    "                  activation=Tanh(),\n",
    "                  weight_init='glorot'),\n",
    "            Dense(neurons=10,\n",
    "                  activation=Linear(),\n",
    "                  weight_init='glorot')],\n",
    "    loss=SoftMaxCrossEntrophy(),\n",
    "    seed=20190119)\n",
    "\n",
    "SMCE_trainer = Trainer(SMCE_model, SGDMomentum(lr=.2, momentum=.9, final_lr=.05, decay_type='exponential'))\n",
    "SMCE_trainer.fit(x_train, train_labels, x_test, test_labels,\n",
    "                 epochs=50,\n",
    "                 eval_every=10,\n",
    "                 batch_size=60,\n",
    "                 seed=20190119)\n",
    "print()\n",
    "eval_model_accuracy(SMCE_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftmaxCrossEntrophy Loss with Tanh Activation and Momentum Optimizer with Linear Decayed Learning and Glorot\n",
      "Weight Initialization\n",
      "\n",
      "Validation loss at epoch 10 is 0.4609834472730396\n",
      "Validation loss at epoch 20 is 0.37871882670153206\n",
      "Validation loss at epoch 30 is 0.2632213925981958\n",
      "Validation loss  increased after epoch 40, previous loss was 0.263; using model from epoch 30\n",
      "Validation loss  increased after epoch 50, previous loss was 0.263; using model from epoch 40\n",
      "\n",
      "Accuracy of model is 96.19%\n"
     ]
    }
   ],
   "source": [
    "print('''SoftmaxCrossEntrophy Loss with Tanh Activation and Momentum Optimizer with Linear Decayed Learning and Glorot\n",
    "Weight Initialization\\n''')\n",
    "SMCE_model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89,\n",
    "                  activation=Tanh(),\n",
    "                  weight_init='glorot'),\n",
    "            Dense(neurons=10,\n",
    "                  activation=Linear(),\n",
    "                  weight_init='glorot')],\n",
    "    loss=SoftMaxCrossEntrophy(),\n",
    "    seed=20190119)\n",
    "\n",
    "SMCE_trainer = Trainer(SMCE_model, SGDMomentum(lr=.2, momentum=.9, final_lr=.05, decay_type='linear'))\n",
    "SMCE_trainer.fit(x_train, train_labels, x_test, test_labels,\n",
    "                 epochs=50,\n",
    "                 eval_every=10,\n",
    "                 batch_size=60,\n",
    "                 seed=20190119)\n",
    "print()\n",
    "eval_model_accuracy(SMCE_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftmaxCrossEntrophy Loss with Tanh Activation and Momentum Optimizer with Exponential Decayed Learning and Glorot\n",
      "Weight Initialization and Dropout\n",
      "\n",
      "Validation loss at epoch 10 is 0.2859862381480503\n",
      "Validation loss at epoch 20 is 0.23188449964034627\n",
      "Validation loss at epoch 30 is 0.19853436461063956\n",
      "Validation loss at epoch 40 is 0.19544069859772156\n",
      "Validation loss  increased after epoch 50, previous loss was 0.195; using model from epoch 40\n",
      "\n",
      "Accuracy of model is 96.96%\n"
     ]
    }
   ],
   "source": [
    "print('''SoftmaxCrossEntrophy Loss with Tanh Activation and Momentum Optimizer with Exponential Decayed Learning and Glorot\n",
    "Weight Initialization and Dropout\\n''')\n",
    "SMCE_model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89,\n",
    "                  activation=Tanh(),\n",
    "                  weight_init='glorot',\n",
    "                  dropout=.8),\n",
    "            Dense(neurons=10,\n",
    "                  activation=Linear(),\n",
    "                  weight_init='glorot')],\n",
    "    loss=SoftMaxCrossEntrophy(),\n",
    "    seed=20190119)\n",
    "\n",
    "SMCE_trainer = Trainer(SMCE_model, SGDMomentum(lr=.2, momentum=.9, final_lr=.05, decay_type='exponential'))\n",
    "SMCE_trainer.fit(x_train, train_labels, x_test, test_labels,\n",
    "                 epochs=50,\n",
    "                 eval_every=10,\n",
    "                 batch_size=60,\n",
    "                 seed=20190119)\n",
    "print()\n",
    "eval_model_accuracy(SMCE_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning Model with Dropout\n",
      "Validation loss at epoch 10 is 0.30719575231290985\n",
      "Validation loss at epoch 20 is 0.25139445476539724\n",
      "Validation loss at epoch 30 is 0.21314303710708046\n",
      "Validation loss at epoch 40 is 0.207260292600183\n",
      "Validation loss at epoch 50 is 0.187464071307511\n",
      "\n",
      "Accuracy of model is 97.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Deep Learning Model with Dropout\")\n",
    "\n",
    "deep_model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=178,\n",
    "                  activation=Tanh(),\n",
    "                  weight_init='glorot',\n",
    "                  dropout=.8),\n",
    "            Dense(neurons=46,\n",
    "                  activation=Tanh(),\n",
    "                  weight_init='glorot',\n",
    "                  dropout=.8),\n",
    "            Dense(neurons=10,\n",
    "                  activation=Linear(),\n",
    "                  weight_init='glorot')],\n",
    "    loss=SoftMaxCrossEntrophy(),\n",
    "    seed=20190119)\n",
    "\n",
    "deep_trainer = Trainer(deep_model, SGDMomentum(lr=.2, momentum=.9, final_lr=.05, decay_type='exponential'))\n",
    "deep_trainer.fit(x_train, train_labels, x_test, test_labels,\n",
    "                 epochs=50,\n",
    "                 eval_every=10,\n",
    "                 batch_size=60,\n",
    "                 seed=20190119)\n",
    "print()\n",
    "eval_model_accuracy(deep_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "\n",
    "img = Image.open('image.png').convert('L').crop(box=(50, 50, 650, 650))\n",
    "img = img.resize((28, 28)).filter(ImageFilter.SHARPEN)\n",
    "imgArrayData = np.array(img.getdata()).astype('uint8')\n",
    "\n",
    "\n",
    "img = np.reshape(imgArrayData, (28, 28))\n",
    "img = Image.fromarray(img)\n",
    "img.show()\n",
    "# imgArrayData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = x_test[84]\n",
    "lst = np.reshape(lst, (28, 28))\n",
    "pic = Image.fromarray(lst)\n",
    "# pic.show()\n",
    "# x_test[84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image number is: 8\n"
     ]
    }
   ],
   "source": [
    "result = deep_trainer.net.forward(imgArrayData, inference=True)\n",
    "print(f\"Input image number is: {np.argmax(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
